{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of Specific Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimation of Single Specific Parameter**\n",
    "\n",
    "This chapter focuses on the estimation of key parameters, including amplitude, phase, time of arrival (delay), and frequency. \n",
    "\n",
    "Both individual parameter estimation and joint estimation of multiple parameters are explored in depth.\n",
    "\n",
    "Building on the foundational concepts introduced in Chapter 3 (Introduction to Estimation), this chapter applies general estimation theory to specific signal parameters such as amplitude and phase, considering cases where the noise is white Gaussian. \n",
    "\n",
    "The emphasis is on Maximum A Posteriori (MAP) and Maximum Likelihood (ML) estimation techniques.\n",
    "\n",
    "We begin by examining the case of a signal within additive white Gaussian noise (WGN), where the parameter is embedded in the signal. \n",
    "\n",
    "Following this, we specialize these results to signal amplitude estimation within WGN for both coherent and noncoherent signals, presenting both MAP and ML estimation approaches. \n",
    "\n",
    "Note that noncoherent estimation refers to estimation with an unknown signal phase.\n",
    "\n",
    "Subsequent sections cover phase and time-delay estimation in WGN, as well as an initial approach to frequency estimation, focusing on estimating a single frequency in WGN. \n",
    "\n",
    "In more typical scenarios, the exact number of signals and noise characteristics may be unknown. \n",
    "\n",
    "The chapter then addresses the simultaneous estimation of multiple parameters in WGN (time permitting).\n",
    "\n",
    "The Cramér-Rao bound is derived, expressed in terms of the Fisher information matrix, whose inverse provides insights into the covariance elements of the estimators.\n",
    "\n",
    "**Estimation of Multiple Parameters**\n",
    "\n",
    "Next, the single-parameter estimation problem, introduced previously sections, is extended to the case of multiple-parameter estimation, where almost all of the operations are linear.\n",
    "\n",
    "Both ML (Maximum Likelihood) and MAP (Maximum A Posteriori) estimates are computed using a discrete linear observation model that is constructed from the parameters to be estimated. \n",
    "\n",
    "We provide computations for an ML estimate where, in general, the noise is zero mean but not white, and is characterized by its covariance matrix. \n",
    "\n",
    "From the Cramér-Rao bound, the ML estimate is found to be unbiased and minimum variance. \n",
    "\n",
    "We consider the case where the parameters are random with a Gaussian probability distribution. \n",
    "\n",
    "The Fisher information matrix is then derived, and the MAP estimate is shown to be unbiased and minimum variance.  \n",
    "\n",
    "Modern estimation techniques are often concerned with providing estimates before all of the data have been observed. This motivates the discussion on sequential estimation in Gaussian noise, which considers the case where an estimate is formed after each new observation, using the current observation and a prior estimate, rather than waiting for all the observations to occur. \n",
    "\n",
    "It is pointed out that this formulation is actually a simple version of the Kalman filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "The contents of the sections in this chapter are based on the following materials.\n",
    "\n",
    "* T. Schonhoff and A. Giordano, _Detection and Estimation Theory and its Applications_. Prentice Hall, 2006 , Chapter 11 and Chapter 12"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
