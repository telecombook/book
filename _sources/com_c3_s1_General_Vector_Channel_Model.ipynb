{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Detection in a General Vector Channel Model\n",
    "\n",
    "The received signal is modeled as an $N$-dimensional vector, $\\vec{r}$ that depends statistically on the transmitted signal vector, $\\vec{s}_m$. \n",
    "\n",
    "In this section, we consider a **general vector channel model**—not limited to the AWGN scenario—and develop the concepts underlying optimal detection.\n",
    "\n",
    "### Signal Transmission and the General Vector Channel\n",
    "\n",
    "Suppose the transmitter has a set of possible **signal vectors**\n",
    "\n",
    "$$\n",
    "\\{\\vec{s}_m, \\, 1 \\le m \\le M\\},\n",
    "$$\n",
    "\n",
    "each corresponding to a **message**. \n",
    "\n",
    "These vectors are transmitted according to certain **a priori probabilities** $P_m$ (other notation $p(\\vec{s}_m)$ or $p(m)$), which capture the likelihood of each message being sent. \n",
    "\n",
    "When a signal vector $\\vec{s}_m$ is transmitted, the received vector $\\vec{r}$ is a random quantity whose statistics are described by the **conditional probability density function (pdf)**\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Pr(\\vec{r} \\mid \\vec{s}_m).\n",
    "}\n",
    "$$\n",
    "\n",
    "Thus, the **overall channel model** is characterized by the statistical relationship between $\\vec{s}_m$ and $\\vec{r}$. The receiver, upon observing $\\vec{r}$, must decide which message was most likely transmitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Function and the Optimal Detector\n",
    "\n",
    "To formalize the detection process, we define a **decision function** (or decision rule) $g(\\vec{r})$, which is a mapping from the observation space $\\mathbb{R}^N$ to the set of messages. The decision rule is expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g: \\mathbb{R}^N &\\rightarrow \\{1, 2, \\ldots, M\\}, \\\\\n",
    "\\vec{r} &\\mapsto \\hat{m}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It indicates that the decision function $g$ takes an $N$-dimensional vector (obtained from the projection of the received waveform $r(t)$ onto an orthonormal basis) as its input and maps it to a message index $\\hat{m}$ in the set $\\{1, 2, \\ldots, M\\}$. \n",
    "\n",
    "When the receiver observes a particular $\\vec{r}$, it declares the transmitted message as \n",
    "\n",
    "$$\n",
    "\\hat{m} = g(\\vec{r})\n",
    "$$\n",
    "\n",
    "The goal of optimal detection is to choose the decision rule $g(\\vec{r})$ so as to minimize the error probability or, equivalently, to maximize the probability of a correct decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Indices\n",
    "\n",
    "Note that in this context, $ m $ and $\\hat{m}$ are typically used as **indices** that label the possible messages.\n",
    "\n",
    "**Message Index:**  \n",
    "The notation $ m $ (with $ 1 \\le m \\le M $) identifies one of the $ M $ possible messages. Each message corresponds to a unique transmitted signal vector $ \\vec{s}_m $. Although each message is originally derived from a sequence of bits (for example, a $ k $-bit sequence when $ M = 2^k $), in the detection and analysis framework we use the index $ m $ to refer to the message.\n",
    "\n",
    "**Detection Process:**  \n",
    "The receiver observes the vector $\\vec{r}$ and makes a decision by choosing an index $\\hat{m}$ that maximizes the posterior probability (or likelihood) given the observation:\n",
    "\n",
    "$$\n",
    "\\hat{m} = \\arg\\max_{1 \\le m \\le M} \\Pr[m|\\vec{r}].\n",
    "$$\n",
    "\n",
    "Here, $\\hat{m}$ is the estimated message index that is declared as the transmitted message.\n",
    "\n",
    "**Mapping to Bit Sequences:**  \n",
    "Although $ m $ (and thus $\\hat{m}$) is an index, there is typically an established mapping between these indices and the actual sequences of bits. For example, if a $ k $-bit message is mapped to an index $ m $, the receiver can convert the detected index $\\hat{m}$ back to its corresponding $ k $-bit binary sequence using the inverse of the mapping used at the transmitter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of a Correct Decision\n",
    "\n",
    "If the receiver decides $\\hat{m}$ upon receiving $\\vec{r}$, the probability that this decision is correct is given by\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Pr[\\text{correct decision} \\mid \\vec{r}] = \\Pr[\\hat{m} \\text{ was sent} \\mid \\vec{r}].\n",
    "}\n",
    "$$\n",
    "\n",
    "That is, given the observation $\\vec{r}$, the probability of being correct is the conditional probability that the transmitted message is $\\hat{m}$.\n",
    "\n",
    "To obtain the overall probability of a correct decision, we average this conditional probability over all possible received vectors $\\vec{r}$ weighted by their marginal probability $p(\\vec{r})$:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Pr[\\text{correct decision}] = \\int \\Pr[\\hat{m} \\text{ was sent} \\mid \\vec{r}] \\, p(\\vec{r}) \\, d\\vec{r}.\n",
    "}\n",
    "$$\n",
    "\n",
    "Since $p(\\vec{r})$ is nonnegative for all $\\vec{r}$, the overall probability of a correct decision is maximized if, for every received $\\vec{r}$, the decision rule maximizes $\\Pr[\\hat{m} \\text{ was sent} \\mid \\vec{r}]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Criterion for the Optimal Detector\n",
    "\n",
    "We can see that since $p(\\vec{r})$ is nonnegative for all $\\vec{r}$, the overall probability of a correct decision is maximized if, for every received $\\vec{r}$, the decision rule *maximizes* $\\Pr[\\hat{m} \\text{ was sent} \\mid \\vec{r}]$.\n",
    "\n",
    "This observation leads directly to the formulation of the **optimal detection rule**. The optimal detector selects the message $m$ that maximizes the posterior probability $\\Pr[m|\\vec{r}]$. Formally, the decision function $g_{\\text{opt}}(\\vec{r})$ is defined as:\n",
    "\n",
    "$$\n",
    "\\hat{m} = g_{\\text{opt}}(\\vec{r}) = \\underset{1 \\leq m \\leq M}{\\arg\\max} \\ \\Pr[m|\\vec{r}].\n",
    "$$\n",
    "\n",
    "In practice, this means that upon receiving $\\vec{r}$, the detector computes $\\Pr[m|\\vec{r}]$ for each $m = 1, 2, \\ldots, M$ and then declares the message corresponding to the largest value of this conditional probability.\n",
    "\n",
    "#### Equivalence in Terms of Signal Vectors\n",
    "\n",
    "Since transmitting message (index) $m$ is equivalent to transmitting the signal vector $\\vec{s}_m$, the optimal decision rule can equivalently be written in terms of these vectors:\n",
    "\n",
    "$$\n",
    "\\hat{m} = g_{\\text{opt}}(\\vec{r}) = \\underset{1 \\leq m \\leq M}{\\arg\\max} \\ \\Pr[\\vec{s}_m|\\vec{r}].\n",
    "$$\n",
    "\n",
    "This formulation emphasizes that the receiver’s decision is based on the likelihood of having received $\\vec{r}$ given that the signal $\\vec{s}_m$ was transmitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Types of Probabilities\n",
    "\n",
    "#### Prior Probability $P_m$\n",
    "\n",
    "- **Definition:**  \n",
    "  The prior probability, denoted by $P_m$, is the probability that the transmitter sends the $m$-th message before any observation is made at the receiver. In other words,\n",
    "\n",
    "  $$\n",
    "  P_m \\equiv p(\\vec{s}_m) \\equiv p(m) = \\Pr[m \\text{ is selected to send}] = \\Pr{\\vec{s}_m \\text{ is selected to send}},\n",
    "  $$\n",
    "\n",
    "  which reflects the statistical likelihood of the $m$-th message being transmitted.\n",
    "\n",
    "\n",
    "- **Role in Detection:**  \n",
    "  The prior probability encapsulates any inherent bias in the message selection process. In many systems, messages are chosen uniformly at random, in which case\n",
    "\n",
    "  $$\n",
    "  P_m = \\frac{1}{M} \\quad \\text{for all } m,\n",
    "  $$\n",
    "\n",
    "  where $M$ is the total number of messages. However, if some messages are more likely to occur than others, $P_m$ will vary accordingly.\n",
    "\n",
    "\n",
    "#### Likelihood Probability $\\Pr(\\vec{r}|\\vec{s}_m)$ or $\\Pr(\\vec{r}|m)$\n",
    "\n",
    "- **Definition:**  \n",
    "  The likelihood probability represents the probability density (or probability, in the discrete case) of receiving the vector $\\vec{r}$ given that the signal corresponding to the $m$-th message (i.e., $\\vec{s}_m$) was transmitted. It is denoted by:\n",
    "\n",
    "  $$\n",
    "  \\Pr(\\vec{r}|\\vec{s}_m) \\quad \\text{or} \\quad \\Pr(\\vec{r}|m).\n",
    "  $$\n",
    "\n",
    "- **Role in Detection:**  \n",
    "  This probability is determined by the channel's statistical behavior. For example, in an AWGN channel, the likelihood is typically modeled as a multivariate Gaussian density centered at $\\vec{s}_m$ with a covariance matrix that depends on the noise variance. It tells us how likely it is to observe $\\vec{r}$ if $\\vec{s}_m$ were transmitted.\n",
    "\n",
    "#### Posterior Probability $\\Pr(\\vec{s}_m|\\vec{r})$ or $\\Pr(m|\\vec{r})$\n",
    "\n",
    "- **Definition:**  \n",
    "  The posterior probability is the probability that the $m$-th message (or equivalently, the signal $\\vec{s}_m$) was transmitted given that the received vector is $\\vec{r}$. It is denoted by:\n",
    "\n",
    "  $$\n",
    "  \\Pr(m|\\vec{r}) \\quad \\text{or} \\quad \\Pr(\\vec{s}_m|\\vec{r}).\n",
    "  $$\n",
    "\n",
    "- **Derivation Using Bayes’ Rule:**  \n",
    "  The posterior probability is computed by applying Bayes’ theorem:\n",
    "\n",
    "  $$\n",
    "  \\Pr(m|\\vec{r}) = \\frac{\\Pr(\\vec{r}|m) \\, P_m}{p(\\vec{r})},\n",
    "  $$\n",
    "\n",
    "  where:\n",
    "  - $\\Pr(\\vec{r}|m)$ is the likelihood.\n",
    "  - $P_m$ is the prior probability.\n",
    "  - $p(\\vec{r})$ is the marginal probability (or evidence), given by\n",
    "\n",
    "    $$\n",
    "    p(\\vec{r}) = \\sum_{m=1}^{M} \\Pr(\\vec{r}|m) \\, P_m.\n",
    "    $$\n",
    "\n",
    "- **Role in Detection:**  \n",
    "  The posterior probability represents the updated belief about which message was transmitted after taking into account the observation $\\vec{r}$. It is the key quantity in the Maximum a Posteriori (MAP) detection rule.\n",
    "\n",
    "Below is an extended explanation of the marginal probability $p(\\vec{r})$ and an updated Markdown table that includes it.\n",
    "\n",
    "#### Marginal Probability $p(\\vec{r})$\n",
    "\n",
    "- **Definition:** \n",
    "The marginal probability $p(\\vec{r})$ represents the unconditional probability density of receiving the vector $\\vec{r}$ regardless of which message was transmitted. It is calculated by averaging (or \"marginalizing\") the likelihood $\\Pr(\\vec{r}|m)$ over all possible messages, each weighted by its corresponding prior probability $P_m$. Mathematically, it is given by:\n",
    "\n",
    "$$\n",
    "p(\\vec{r}) = \\sum_{m=1}^{M} \\Pr(\\vec{r}|m) \\, P_m.\n",
    "$$\n",
    "\n",
    "- **Role in Detection:** \n",
    "This term plays a crucial role in Bayes' theorem, serving as a normalizing constant to ensure that the posterior probabilities sum to one. It provides a measure of how likely the observation $\\vec{r}$ is under the entire statistical model of the transmission process.\n",
    "\n",
    "#### Conditional Probability (Correction Detection Probability) $\\Pr(\\hat{m} \\text{ was sent} \\,|\\, \\vec{r})$\n",
    "\n",
    "- **Definition:**  \n",
    "  Once the receiver processes $\\vec{r}$, it makes a decision and declares $\\hat{m}$ as the transmitted message. The probability\n",
    "\n",
    "  $$\n",
    "  \\Pr(\\hat{m} \\text{ was sent} \\,|\\, \\vec{r})\n",
    "  $$\n",
    "\n",
    "  is the probability that the message corresponding to the decision $\\hat{m}$ is indeed the one that was transmitted, given the received vector $\\vec{r}$.\n",
    "\n",
    "  This probability is often referred to as the **conditional probability of correct detection** (or simply the conditional correctness probability) given $\\vec{r}$. \n",
    "\n",
    "- **Role in Performance Analysis:**  \n",
    "  This quantity directly reflects the confidence of the detector in its decision for a given observation $\\vec{r}$. The overall performance (i.e., the overall probability of a correct decision) is obtained by averaging $\\Pr(\\hat{m} \\text{ was sent} \\,|\\, \\vec{r})$ over all possible received vectors:\n",
    "\n",
    "  $$\n",
    "  \\Pr[\\text{correct decision}] = \\int \\Pr(\\hat{m} \\text{ was sent} \\,|\\, \\vec{r}) \\, p(\\vec{r}) \\, d\\vec{r}.\n",
    "  $$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
